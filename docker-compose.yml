# HIGH-014 FIX: Startup Order Documentation
# ==============================================================================
# CRITICAL: Services must start in the following order (enforced by depends_on):
# 1. postgres-db (foundation - no dependencies)
# 2. minio (storage - no dependencies)
# 3. metrics-collector (depends on postgres-db)
# 4. llm-service (depends on postgres-db)
# 5. embedding-service (depends on postgres-db)
# 6. reverse-proxy (depends on postgres-db, minio, metrics-collector, llm-service, embedding-service)
# 7. dashboard-backend (depends on postgres-db, minio, metrics-collector, llm-service, embedding-service, reverse-proxy)
# 8. dashboard-frontend (depends on reverse-proxy) <-- NOW ENFORCED VIA depends_on
# 9. n8n (depends on postgres-db, llm-service, embedding-service, minio)
# 10. self-healing-agent (depends on all services - starts last)
#
# IMPORTANT: All services implement retry logic for database and service connections.
# Healthchecks are robust (see HIGH-010 fix) and properly handle timeouts.
# ==============================================================================

networks:
  arasul-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/24

volumes:
  arasul-postgres:
  arasul-minio:
  arasul-n8n:
  arasul-llm-models:
  arasul-embeddings-models:
  arasul-metrics:
  arasul-qdrant:
  arasul-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /arasul/logs
  arasul-letsencrypt:

services:
  # 1. PostgreSQL - Telemetry and Audit Database
  postgres-db:
    image: postgres:16-alpine
    container_name: postgres-db
    hostname: postgres-db
    restart: always
    networks:
      - arasul-net
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_MAX_CONNECTIONS: ${POSTGRES_MAX_CONNECTIONS}
    volumes:
      - arasul-postgres:/var/lib/postgresql/data
      - ./services/postgres/init:/docker-entrypoint-initdb.d
      - ./services/postgres/migrations:/migrations
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 2s
      retries: 3
    deploy:
      resources:
        limits:
          memory: ${RAM_LIMIT_POSTGRES}
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 2. MinIO - Object Storage
  minio:
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    restart: always
    networks:
      - arasul-net
    ports:
      - "9001:9001"  # MinIO Console - Direct access
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_BROWSER: ${MINIO_BROWSER}
    volumes:
      - arasul-minio:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 1s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 2.5 Qdrant - Vector Database for RAG
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    hostname: qdrant
    restart: always
    networks:
      - arasul-net
    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC API
    volumes:
      - arasul-qdrant:/qdrant/storage
    environment:
      QDRANT__SERVICE__GRPC_PORT: "6334"
      QDRANT__SERVICE__HTTP_PORT: "6333"
    healthcheck:
      test: ["CMD", "test", "-f", "/qdrant/storage/raft_state.json"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 3. Metrics Collector
  metrics-collector:
    build:
      context: ./services/metrics-collector
      dockerfile: Dockerfile
    container_name: metrics-collector
    hostname: metrics-collector
    restart: always
    networks:
      - arasul-net
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      METRICS_INTERVAL_LIVE: ${METRICS_INTERVAL_LIVE}
      METRICS_INTERVAL_PERSIST: ${METRICS_INTERVAL_PERSIST}
      LOG_LEVEL: ${LOG_LEVEL}
    volumes:
      - /sys:/host/sys:ro
      - /proc:/host/proc:ro
      - arasul-metrics:/cache
    depends_on:
      postgres-db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9100/health"]
      interval: 10s
      timeout: 1s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 4. LLM Service (Ollama)
  llm-service:
    build:
      context: ./services/llm-service
      dockerfile: Dockerfile
    container_name: llm-service
    hostname: llm-service
    restart: always
    networks:
      - arasul-net
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
      OLLAMA_MODELS: /models
      LLM_MODEL: ${LLM_MODEL:-llama2}
      LLM_KEEP_ALIVE_SECONDS: ${LLM_KEEP_ALIVE_SECONDS:-300}
    volumes:
      - arasul-llm-models:/root/.ollama
      - ./services/llm-service/healthcheck.sh:/healthcheck.sh:ro
      - ./data/models:/host-models:ro
    runtime: nvidia
    deploy:
      resources:
        limits:
          cpus: '${CPU_LIMIT_LLM}'
          memory: ${RAM_LIMIT_LLM}
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      postgres-db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "/bin/bash", "/healthcheck.sh"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 300s
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 5. Embedding Service
  embedding-service:
    build:
      context: ./services/embedding-service
      dockerfile: Dockerfile
    container_name: embedding-service
    hostname: embedding-service
    restart: always
    networks:
      - arasul-net
    environment:
      MODEL_NAME: ${EMBEDDING_MODEL}
      SERVICE_PORT: ${EMBEDDING_SERVICE_PORT}
      SERVICE_URL: http://localhost:${EMBEDDING_SERVICE_PORT}
      VECTOR_SIZE: ${EMBEDDING_VECTOR_SIZE}
      MAX_INPUT_TOKENS: ${EMBEDDING_MAX_INPUT_TOKENS}
      # Jetson Orin GPU activation
      CUDA_VISIBLE_DEVICES: 0
      TORCH_CUDA_ARCH_LIST: "8.7"
    volumes:
      - arasul-embeddings-models:/models
      - ./services/embedding-service/healthcheck.sh:/healthcheck.sh:ro
    runtime: nvidia
    deploy:
      resources:
        limits:
          cpus: '${CPU_LIMIT_EMBEDDING}'
          memory: ${RAM_LIMIT_EMBEDDING}
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      postgres-db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "/bin/bash", "/healthcheck.sh"]
      interval: 15s
      timeout: 3s
      retries: 3
      start_period: 300s
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 5.5 Document Indexer - Automatic document indexing for RAG
  document-indexer:
    build:
      context: ./services/document-indexer
      dockerfile: Dockerfile
    container_name: document-indexer
    hostname: document-indexer
    restart: always
    networks:
      - arasul-net
    environment:
      MINIO_HOST: ${MINIO_HOST}
      MINIO_PORT: ${MINIO_PORT}
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      DOCUMENT_INDEXER_MINIO_BUCKET: ${DOCUMENT_INDEXER_MINIO_BUCKET}
      QDRANT_HOST: ${QDRANT_HOST}
      QDRANT_PORT: ${QDRANT_PORT}
      QDRANT_COLLECTION_NAME: ${QDRANT_COLLECTION_NAME}
      EMBEDDING_SERVICE_HOST: ${EMBEDDING_SERVICE_HOST}
      EMBEDDING_SERVICE_PORT: ${EMBEDDING_SERVICE_PORT}
      EMBEDDING_VECTOR_SIZE: ${EMBEDDING_VECTOR_SIZE}
      DOCUMENT_INDEXER_INTERVAL: ${DOCUMENT_INDEXER_INTERVAL}
      DOCUMENT_INDEXER_CHUNK_SIZE: ${DOCUMENT_INDEXER_CHUNK_SIZE}
      DOCUMENT_INDEXER_CHUNK_OVERLAP: ${DOCUMENT_INDEXER_CHUNK_OVERLAP}
    depends_on:
      minio:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      embedding-service:
        condition: service_healthy
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 6. Reverse Proxy (Traefik) - Starts AFTER core services, BEFORE dashboards
  reverse-proxy:
    image: traefik:v2.11
    container_name: reverse-proxy
    hostname: reverse-proxy
    restart: always
    networks:
      - arasul-net
    command:
      - "--configFile=/etc/traefik/traefik.yml"
    ports:
      - "80:80"
      - "443:443"
      - "127.0.0.1:8080:8080"  # Dashboard only on localhost
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./config/traefik:/etc/traefik:ro
      - arasul-letsencrypt:/letsencrypt
      - ./logs:/arasul/logs
    # HIGH-014 FIX: Ensure all backend services are healthy before starting reverse proxy
    depends_on:
      postgres-db:
        condition: service_healthy
      minio:
        condition: service_healthy
      metrics-collector:
        condition: service_healthy
      llm-service:
        condition: service_healthy
      embedding-service:
        condition: service_started  # Changed: Model loading can take time
    healthcheck:
      test: ["CMD", "traefik", "healthcheck", "--ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 7. Dashboard Backend
  dashboard-backend:
    build:
      context: ./services/dashboard-backend
      dockerfile: Dockerfile
    container_name: dashboard-backend
    hostname: dashboard-backend
    restart: always
    networks:
      - arasul-net
    # Add docker group (994) to allow access to docker.sock for service status monitoring
    group_add:
      - "994"
    environment:
      NODE_ENV: production
      PORT: ${DASHBOARD_BACKEND_PORT}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      LLM_SERVICE_HOST: ${LLM_SERVICE_HOST}
      LLM_SERVICE_PORT: ${LLM_SERVICE_PORT}
      EMBEDDING_SERVICE_HOST: ${EMBEDDING_SERVICE_HOST}
      EMBEDDING_SERVICE_PORT: ${EMBEDDING_SERVICE_PORT}
      MINIO_HOST: ${MINIO_HOST}
      MINIO_PORT: ${MINIO_PORT}
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      N8N_HOST: ${N8N_HOST}
      N8N_PORT: ${N8N_PORT}
      QDRANT_HOST: ${QDRANT_HOST}
      QDRANT_PORT: ${QDRANT_PORT}
      QDRANT_COLLECTION_NAME: ${QDRANT_COLLECTION_NAME}
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXPIRY: ${JWT_EXPIRY}
      ADMIN_USERNAME: ${ADMIN_USERNAME}
      SYSTEM_VERSION: ${SYSTEM_VERSION}
      BUILD_HASH: ${BUILD_HASH}
      LOG_LEVEL: ${LOG_LEVEL}
      ENV_FILE_PATH: /arasul/config/.env
      COMPOSE_PROJECT_DIR: /home/arasul/arasul/arasul-jet
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./.env:/arasul/config/.env
      - ./config:/config:ro
      - ./data/updates:/arasul/updates
      - ./data/backups:/arasul/backups:ro
    depends_on:
      postgres-db:
        condition: service_healthy
      minio:
        condition: service_healthy
      metrics-collector:
        condition: service_healthy
      llm-service:
        condition: service_healthy
      embedding-service:
        condition: service_started  # Changed from service_healthy - model loading can take time
      reverse-proxy:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://127.0.0.1:3001/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '${CPU_LIMIT_DASHBOARD}'
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.api.rule=PathPrefix(`/api`)"
      - "traefik.http.routers.api.priority=10"
      - "traefik.http.routers.api.entrypoints=websecure"
      - "traefik.http.routers.api.tls=true"
      - "traefik.http.services.api.loadbalancer.server.port=3001"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 8. Dashboard Frontend
  dashboard-frontend:
    build:
      context: ./services/dashboard-frontend
      dockerfile: Dockerfile
    container_name: dashboard-frontend
    hostname: dashboard-frontend
    restart: always
    networks:
      - arasul-net
    # Note: React ENV vars are embedded at BUILD time, not runtime
    # Frontend uses dynamic detection from window.location
    depends_on:
      reverse-proxy:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "test", "-f", "/usr/share/nginx/html/index.html"]
      interval: 10s
      timeout: 1s
      retries: 3
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=PathPrefix(`/`) && !PathPrefix(`/n8n`) && !PathPrefix(`/api`)"
      - "traefik.http.routers.frontend.priority=1"
      - "traefik.http.routers.frontend.entrypoints=websecure"
      - "traefik.http.routers.frontend.tls=true"
      - "traefik.http.services.frontend.loadbalancer.server.port=3000"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 9. n8n Workflow Engine
  n8n:
    build:
      context: ./services/n8n
      dockerfile: Dockerfile
    container_name: n8n
    hostname: n8n
    restart: always
    networks:
      - arasul-net
    ports:
      - "5678:5678"
    environment:
      N8N_HOST: ${N8N_HOST}
      N8N_PORT: ${N8N_PORT}
      N8N_PROTOCOL: http
      N8N_BASIC_AUTH_ACTIVE: ${N8N_BASIC_AUTH_ACTIVE}
      N8N_BASIC_AUTH_USER: ${N8N_BASIC_AUTH_USER}
      N8N_BASIC_AUTH_PASSWORD: ${N8N_BASIC_AUTH_PASSWORD}
      WEBHOOK_URL: http://${N8N_HOST}:${N8N_WEBHOOK_PORT}
      N8N_ENCRYPTION_KEY: ${N8N_ENCRYPTION_KEY}
      EXECUTIONS_DATA_SAVE_ON_SUCCESS: all
      EXECUTIONS_DATA_SAVE_ON_ERROR: all
      EXECUTIONS_DATA_SAVE_MANUAL_EXECUTIONS: "true"
      # Custom nodes are baked into the image via Dockerfile
      N8N_CUSTOM_EXTENSIONS: /custom-nodes
    volumes:
      - arasul-n8n:/home/node/.n8n
      # Mount credential templates
      - ./services/n8n/credentials:/custom-credentials:ro
      # Mount workflow templates
      - ./services/n8n/templates:/custom-templates:ro
    depends_on:
      postgres-db:
        condition: service_healthy
      llm-service:
        condition: service_healthy
      embedding-service:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5678/healthz"]
      interval: 15s
      timeout: 2s
      retries: 3
    deploy:
      resources:
        limits:
          memory: ${RAM_LIMIT_N8N}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.n8n.rule=PathPrefix(`/n8n`)"
      - "traefik.http.routers.n8n.priority=100"
      - "traefik.http.routers.n8n.entrypoints=websecure"
      - "traefik.http.routers.n8n.tls=true"
      - "traefik.http.services.n8n.loadbalancer.server.port=5678"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"

  # 10. Self-Healing Engine
  self-healing-agent:
    build:
      context: ./services/self-healing-agent
      dockerfile: Dockerfile
    container_name: self-healing-agent
    hostname: self-healing-agent
    restart: always
    networks:
      - arasul-net
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      SELF_HEALING_INTERVAL: ${SELF_HEALING_INTERVAL}
      SELF_HEALING_ENABLED: ${SELF_HEALING_ENABLED}
      LOG_LEVEL: ${SELF_HEALING_LOG_LEVEL}
      METRICS_COLLECTOR_HOST: metrics-collector
      METRICS_COLLECTOR_PORT: 9100
      DISK_WARNING_PERCENT: ${DISK_WARNING_PERCENT}
      DISK_CLEANUP_PERCENT: ${DISK_CLEANUP_PERCENT}
      DISK_CRITICAL_PERCENT: ${DISK_CRITICAL_PERCENT}
      DISK_REBOOT_PERCENT: ${DISK_REBOOT_PERCENT}
      HEARTBEAT_PORT: ${SELF_HEALING_HEARTBEAT_PORT:-9200}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./logs:/arasul/logs
      - /sys:/host/sys:ro
      - /proc:/host/proc:ro
      - /media:/media:ro
      - /mnt:/mnt:ro
      - ./data/updates:/arasul/updates
      - ./data/backups:/arasul/backups
    devices:
      - /dev/bus/usb:/dev/bus/usb
    cap_add:
      - SYS_ADMIN   # Required for system management operations
      - SYS_BOOT    # Required for reboot capability
      - SYS_NICE    # Required for process priority management
    depends_on:
      postgres-db:
        condition: service_healthy
      metrics-collector:
        condition: service_healthy
      dashboard-backend:
        condition: service_healthy
      llm-service:
        condition: service_healthy
      embedding-service:
        condition: service_healthy
      n8n:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "/app/heartbeat.py", "--test"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "10"
